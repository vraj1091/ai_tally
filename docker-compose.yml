version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ai-tally-backend
    ports:
      - "8000:8000"
    # Enable host.docker.internal on Linux (for Ollama access)
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - TALLY_HOST=${TALLY_HOST:-localhost}
      - TALLY_PORT=${TALLY_PORT:-9000}
      - TALLY_REMOTE_ENABLED=${TALLY_REMOTE_ENABLED:-True}
      # Ollama runs on host, accessible via host.docker.internal
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      # Use phi4:14b (requires ~20GB RAM, user has 32GB)
      - OLLAMA_MODEL=${OLLAMA_MODEL:-phi4:14b}
      # Use PostgreSQL for production (recommended) or SQLite for development
      # PostgreSQL: postgresql://tally_user:YourPassword@host.docker.internal:5432/ai_tally
      # SQLite: sqlite:////app/data/database.db
      - DB_URL=${DB_URL:-postgresql://tally_user:YourStrongPassword123@host.docker.internal:5432/ai_tally}
      - API_HOST=0.0.0.0
      - API_PORT=8000
      - DEBUG=${DEBUG:-False}
      - CORS_ORIGINS=${CORS_ORIGINS:-http://107.21.87.222:5173,http://107.21.87.222,http://107.21.87.222:80,ws://107.21.87.222:8000,wss://107.21.87.222:8000,http://localhost:5173,http://localhost:3000}
      # SECURITY: Set strong secrets in production! Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
      - SECRET_KEY=${SECRET_KEY:-Tl4DdPr0dUcT10n_S3cR3t_K3y_Ch4ng3_M3_2024}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-Jwt_S3cR3t_K3y_F0r_A1_T4lly_2024}
      - ACCESS_TOKEN_EXPIRE_MINUTES=${ACCESS_TOKEN_EXPIRE_MINUTES:-1440}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - SECURE_HEADERS=True
      # Force CPU mode for AI
      - CUDA_VISIBLE_DEVICES=
      - TORCH_DEVICE=cpu
    volumes:
      - backend_data:/app/data
      - backend_logs:/app/logs
      - backend_uploads:/app/uploads
      - backend_chroma:/app/chroma_db
      - backend_cache:/app/cache
    restart: unless-stopped
    networks:
      - app-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        # Use empty VITE_API_URL so frontend uses relative /api path via nginx
        - VITE_API_URL=
        - VITE_WS_URL=${VITE_WS_URL:-ws://107.21.87.222}
    container_name: ai-tally-frontend
    ports:
      - "5173:80"
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  backend_data:
  backend_logs:
  backend_uploads:
  backend_chroma:
  backend_cache:

